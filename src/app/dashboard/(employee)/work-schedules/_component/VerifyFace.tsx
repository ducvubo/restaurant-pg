'use client';

import React, { useEffect, useRef, useState, forwardRef } from 'react';
import {
  AlertDialog,
  AlertDialogAction,
  AlertDialogCancel,
  AlertDialogContent,
  AlertDialogDescription,
  AlertDialogFooter,
  AlertDialogHeader,
  AlertDialogTitle,
  AlertDialogTrigger,
} from '@/components/ui/alert-dialog';
import Webcam from 'react-webcam';
import * as faceapi from 'face-api.js';
import { useRouter } from 'next/navigation';
import { deleteCookiesAndRedirect } from '@/app/actions/action';
import { toast } from '@/hooks/use-toast';
import { useLoading } from '@/context/LoadingContext';
import { debounce } from 'lodash';
import { Button } from '@/components/ui/button';
import { IEmployee } from '../../employees/employees.interface';
import { checkInWork } from '../work-schedule.api';
import { Camera, Upload } from 'lucide-react';

const VerifyFace = forwardRef<HTMLDivElement>((_, ref) => {
  const { setLoading } = useLoading();
  const router = useRouter();
  const webcamRef = useRef<Webcam | null>(null);
  const [modelsLoaded, setModelsLoaded] = useState(false);
  const [isCapturing, setIsCapturing] = useState(false);
  const [capturedImage, setCapturedImage] = useState<string | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [webcamReady, setWebcamReady] = useState(false);
  const [isOpen, setIsOpen] = useState(false);

  useEffect(() => {
    const loadModels = async () => {
      try {
        const MODEL_URL = '/models';
        await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
        setModelsLoaded(true);
        console.log('M√¥ h√¨nh face-api.js t·∫£i th√†nh c√¥ng');
      } catch (err) {
        console.error('L·ªói t·∫£i m√¥ h√¨nh:', err);
        setError('Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh nh·∫≠n di·ªán khu√¥n m·∫∑t');
      }
    };
    loadModels();
  }, []);

  useEffect(() => {
    if (webcamRef.current) {
      console.log('webcamRef ƒë√£ ƒë∆∞·ª£c g√°n:', webcamRef.current);
      setWebcamReady(true);
    } else {
      console.log('webcamRef v·∫´n l√† null');
    }
  }, [webcamRef.current]);

  // Reset states when dialog opens
  useEffect(() => {
    if (isOpen) {
      setCapturedImage(null); // Reset capturedImage to allow new capture
      setError(null); // Clear any previous errors
      setIsCapturing(false); // Reset capturing state
    }
  }, [isOpen]);

  const debouncedCaptureAndVerify = debounce(async () => {
    if (!webcamRef.current || isCapturing) {
      console.log('B·ªè qua ch·ª•p ·∫£nh:', { webcamRef: !!webcamRef.current, isCapturing });
      return;
    }

    const video = webcamRef.current.video;
    if (!video || video.readyState !== 4) {
      console.log('Webcam ch∆∞a s·∫µn s√†ng:', video?.readyState);
      return;
    }

    try {
      setIsCapturing(true);
      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
      console.log('S·ªë khu√¥n m·∫∑t ph√°t hi·ªán:', detections.length);

      if (detections.length > 0) {
        const imageSrc = webcamRef.current.getScreenshot();
        if (imageSrc) {
          setCapturedImage(imageSrc);
          await verifyFace(imageSrc);
        } else {
          console.log('Kh√¥ng ch·ª•p ƒë∆∞·ª£c ·∫£nh');
          setError('Kh√¥ng th·ªÉ ch·ª•p ·∫£nh');
        }
      } else {
        setError('Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t, vui l√≤ng th·ª≠ l·∫°i');
      }
    } catch (err) {
      console.error('L·ªói ph√°t hi·ªán khu√¥n m·∫∑t:', err);
      setError('L·ªói khi ch·ª•p ·∫£nh khu√¥n m·∫∑t');
    } finally {
      setIsCapturing(false);
    }
  }, 200);

  useEffect(() => {
    if (!modelsLoaded || !webcamReady || capturedImage || !isOpen) {
      console.log('Kh√¥ng ch·∫°y detection:', {
        modelsLoaded,
        webcamReady,
        capturedImage: !!capturedImage,
        isOpen,
      });
      return;
    }

    const interval = setInterval(() => {
      debouncedCaptureAndVerify();
    }, 500);

    return () => {
      console.log('D·ªçn d·∫πp interval');
      clearInterval(interval);
      debouncedCaptureAndVerify.cancel();
    };
  }, [modelsLoaded, webcamReady, capturedImage, isOpen]);

  const verifyFace = async (imageSrc: string) => {
    setLoading(true);
    try {
      const formData = new FormData();
      const response = await fetch(imageSrc);
      const blob = await response.blob();
      formData.append('image', blob, `verify_face.jpg`);

      const res = await fetch('/api/verify-face', {
        method: 'POST',
        body: formData,
      });

      const data: IBackendRes<IEmployee> = await res.json();
      console.log("üöÄ ~ verifyFace ~ data:", data);

      if (data.statusCode === 201 && data.data) {
        const resTimeSheet = await checkInWork({
          _id: data?.data?._id as string,
          date: new Date(),
        });

        if (resTimeSheet.statusCode === 201 || resTimeSheet.statusCode === 200) {
          toast({
            title: 'Th√†nh c√¥ng',
            description: `Nh√¢n vi√™n: ${data.data.epl_name}, Ca l√†m vi·ªác: ${resTimeSheet.data?.workingShift.wks_name}`,
            variant: 'default',
          });
          setIsOpen(false);
          router.push('/dashboard/work-schedules');
        } else {
          throw new Error(resTimeSheet.message || 'Kh√¥ng t√¨m th·∫•y ca l√†m vi·ªác');
        }
      } else {
        throw new Error('Kh√¥ng th·ªÉ x√°c th·ª±c khu√¥n m·∫∑t');
      }
    } catch (err) {
      console.error('L·ªói g·ª≠i API:', err);
      toast({
        title: 'Th·∫•t b·∫°i',
        description: 'Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn server, vui l√≤ng th·ª≠ l·∫°i sau',
        variant: 'destructive',
      });
      setCapturedImage(null); // Reset ƒë·ªÉ cho ph√©p ch·ª•p l·∫°i
    } finally {
      setLoading(false);
    }
  };

  return (
    <div ref={ref}>
      <AlertDialog open={isOpen} onOpenChange={setIsOpen}>
        <AlertDialogTrigger asChild>
          <Button variant={'outline'} onClick={() => setIsOpen(true)} className="flex items-center gap-2">
            <Camera className="w-4 h-4" />
            Ch·∫•m c√¥ng
          </Button>
        </AlertDialogTrigger>
        <AlertDialogContent>
          <AlertDialogHeader>
            <AlertDialogTitle>Ch·∫•m c√¥ng</AlertDialogTitle>
            <AlertDialogDescription>
              Vui l√≤ng nh√¨n v√†o webcam ƒë·ªÉ ch·∫•m c√¥ng.
            </AlertDialogDescription>
          </AlertDialogHeader>
          <div className="flex flex-col items-center">
            {error && <p className="text-red-500 mb-4">{error}</p>}
            <Webcam
              audio={false}
              ref={webcamRef}
              screenshotFormat="image/jpeg"
              width={640}
              height={480}
              videoConstraints={{
                facingMode: 'user',
              }}
              className="mb-4"
              onUserMedia={() => {
                console.log('Webcam ƒë√£ kh·ªüi ƒë·ªông');
                setWebcamReady(true);
              }}
              onUserMediaError={(err) => {
                console.error('L·ªói webcam:', err);
                setError('Kh√¥ng th·ªÉ truy c·∫≠p webcam');
              }}
            />
            {isCapturing && <p className="mb-4">ƒêang ch·ª•p ·∫£nh...</p>}
          </div>
          <AlertDialogFooter>
            <AlertDialogCancel onClick={() => setIsOpen(false)}>H·ªßy</AlertDialogCancel>
          </AlertDialogFooter>
        </AlertDialogContent>
      </AlertDialog>
    </div>
  );
});

VerifyFace.displayName = 'VerifyFace';
export default VerifyFace;